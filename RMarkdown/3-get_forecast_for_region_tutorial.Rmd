---
title: 'CLIMARK Tutorial: Get forecast for region'
author: "Victoria Scholl"
date: "6/20/2018"
output:
  html_document: default
  pdf_document: default
---

Because this is an RMarkdown File, we need to define out working directory first.  This is the place on your computer where your input files are located for this tutorial, and it is also where the output files will be written. Instead of typing out the entire path to every file that we need ("absolute" paths), you can just use their filenames or locations within this working directory ("relative" paths) since we are setting this working directory as our starting point for the rest of the tutorial. 

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo=TRUE,
                      message=FALSE,
                      warning=FALSE,
                      results = 'hide')

knitr::opts_knit$set(root.dir = 'c:/aWhere/projects/climark')
```

# Introduction

This tutorial pulls forecasted weather data from the aWhere API for a specific timespan and area of interest. 

# Code 

## Install / load R packages

First, install the aWhere R packages. 

```{r install_aWhere_packages, eval=FALSE}
# install aWhere R packages
library(devtools)
devtools::install_github("aWhereAPI/aWhere-R-Library")
devtools::install_github("aWhereAPI/aWhere-R-Charts")

```
This code would automatically check to see if the necessary packages are installed and if not, install them

```{r check_install_packages, eval = FALSE}

list.of.packages.CRAN = c("dplyr", "ggmap", "tibble", "wicket", "ggplot2", 'raster',"knitr")

new.packages.CRAN = list.of.packages.CRAN[!(list.of.packages.CRAN %in% installed.packages()[,"Package"])]
if(length(new.packages.CRAN)) install.packages(new.packages.CRAN)


list.of.packages.Github = c("aWhereAPI", "aWhereCharts")

new.packages.Github = list.of.packages.Github[!(list.of.packages.Github %in% installed.packages()[,"Package"])]
if(length(new.packages.Github) > 0) {
  for (x in 1:length(new.packages.Github)) {
    if (new.packages.Github[x] == 'aWhereAPI') {
      devtools::install_github("aWhereAPI/aWhere-R-Library")
    } else if (new.packages.Github[x] == 'aWhereCharts') {
      devtools::install_github("aWhereAPI/aWhere-R-Charts")
    }
  }
} 
```

Load the R packages that contain functions used in this script.

```{r}
library(dplyr)
library(ggmap)
library(tibble)
library(wicket)
library(ggplot2)
library(raster)
library(knitr)
library(aWhereAPI)
library(aWhereCharts)
```

## Define input files and parameters

Use the *source* function to load R functions that are located on your local machine. For this tutorial, there are a few functions within the *0-supporting_functions.R* file. There is a zero in the beginning of this filename so it appears at the top when files are sorted alphabetically. 

```{r load.functions}
# load external R functions in local file
source("src/0-supporting_functions.R")

dir.create(path = 'figures/',showWarnings = FALSE, recursive = TRUE)
dir.create(path = 'shapefiles', showWarnings = FALSE, recursive = TRUE)
```

To pull data from the aWhere API, you'll need a Consumer Key and Secret, like a username and password. Put these in a text file with the following format: line 1 is the Consumer Key, line 2 is the Consumer Secret, and line 3 is a blank line. Set the *credentials.file* variable equal to the name of this text file. Place your credentials file in your working directory. 

```{r set.credentials.file}
# filename containing your aWhere credientials (key and secret)
credentials.file <- 'c:/aWhere/credentials/credentials.txt'

# load the aWhere API credentials file 
aWhereAPI::load_credentials(credentials.file)
```

What are the starting and ending days that define the duration of the forecast? Also specify the range of years over which to calculate the long-term normal values. 

```{r}
# The forecast is limited to a maximum number of 7 days from today. 
# starting day can be "today" or "tomorrow"
days <- GetDays(starting.day = "yesterday",
                forecast.days = 7)


# "years"" is a vector with the starting year in position 1 and the ending
# year in position 2, for the long-term analysis. 
years <- c(2010, 2017)
```

This script not only pulls forecast data on a daily timestep; it also calculates aggregated forecast summaries. For a 3-day forecast, the forecasted daily precip will be summed over the course of three days. For a 7-day forecast, the forecasted daily precip will be summed over the course of seven days. Here, specify which n-day forecasts you would like to aggregate. 

```{r}
# define the length of forecast(s) to generate in a vector. 
# For a 7-day and 3-day forecast, n.day.forecasts <- c(7, 3)
n.day.forecasts <- c(7, 3)
```

Specify the template data filename containing the geographic location data.

```{r}
# define template data filename
template.file <- "templateFiles/CLIMARKonlyWardTemplate.csv"
``` 

Here is a list of all wards in the CLIMARK area: 

```{r results = TRUE}
# read the template data 
template.place <- utils::read.csv(template.file,
                                  stringsAsFactors=FALSE) 

print("Wards in data set: ")

print(unique(template.place$WARD_NAME))
```

To select subarea(s) of interest, list their names in this vector. For now, these subareas are limited to ward names. 

```{r}
subarea.select <- c("LOIYANGALANI", "GOLBO")
subarea.select <- "KARARE" 
```

Read the template data. Filter the data to keep only the grid cells within the subarea of interest. 

```{r}
# filter the template for subarea(s) of interest
if (!identical(subarea.select, "ENTIRE_REGION")){ 
  
  template.place <- template.place %>% 
    dplyr::filter(WARD_NAME %in% subarea.select) 
  
} 
```

Let's calculate how many grids are located within the selected subarea(s). 

```{r results = TRUE}
print(paste0("Your forecast will pull ", as.character(nrow(template.place)), 
      " grids from the aWhere API"))
```

Specify the base filename for outputs. It currently incorporates the name(s) of the subarea(s) of interest, but you can set it to be anything. 

```{r}
filename.out <- paste("AOI_Forecast",
                      paste(subarea.select, collapse="_"),
                      sep = "_")
```

When plotting the weather data, we will first display a geographic base map. You can either define (1) the latitude and longitude of the center of your area of interest OR (2) the country name, in addition to a zoom values for the base map. For the entire CLIMARK region, a latitude of 2.5, longitude of 38, and zoom of 7 work well. 

```{r}
# specific latitude and longitude coordinates and zoom value for the base map 
map.lat <- 2.5
map.lon <- 38
map.zoom <- 7
```

To make sure you have the right base map coordinates, let's display it: 
```{r results = TRUE, fig.align="center"}
# create the base map 
base.map = ggmap::get_map(location = c(lon = map.lon,  lat = map.lat), 
                   zoom = map.zoom, 
                   color = "bw")

# display map of region
gg.map <- ggmap(base.map)
gg.map
```

Or you can set *location* = "kenya" instead of using a specific latitute and longitude.  However, this functionality is limited and is subject to the Google API.  Instead, we show code that relies on pulling a shapefile of the respective country, extracting a bounding box, and then using that information to query a different map source.  This method also allows the file to be saved locally so the map information will only have to be pulled once

```{r results = TRUE, fig.align="center"}
#Query list of all available countries
country.codes <- raster::getData('ISO3')

#We are not going to use this function because it is dependent on Google's API
#which we have no control over and there are query limits.  Instead we will use
#the raster package to query for a shapefile of the country and then will
#extract the bounding box to use for the call

#base.map <- ggmap::get_map(location = "Kenya", zoom = 6, color = "bw",source = 'google')

#Specify what county the boundary is requested for.  By altering the query below
#it is possible to only request the region for a subset of the country or for
#multiple countries
#
# The Download = TRUE option will make it so that if the user runs the script multiple times the file
# will be loaded from local files after the first run
countryOfInterest.name <- 'Kenya'

countryOfInterest.raster <- raster::getData('GADM'
                                            ,country=country.codes[country.codes$NAME == countryOfInterest.name,'ISO3']
                                            ,level=0
                                            ,download = TRUE
                                            ,path = 'shapefiles/')

countryOfInterest.extent <- raster::extent(countryOfInterest.raster)

# create the base map 

sbbox <- ggmap::make_bbox(lon = c(countryOfInterest.extent[1]
                           ,countryOfInterest.extent[2])
                          ,lat = c(countryOfInterest.extent[3]
                                  ,countryOfInterest.extent[4]))

base.map <- ggmap::get_map(location = sbbox, maptype = "toner", source = "stamen")

gg.map <- ggmap(base.map)
gg.map

```

Set thresholds for different variables during mapping. For instance, we want our mapped range of precipitation data to be from 0 to 300 mm. 

```{r}
thresh.precip.max <- 300 # [mm]
thresh.precip.min <- 0 # [mm]
```

## Processing steps 

Pull the aWhere forecast data for the specified location and timespan. The R function that we use to pull the data is *generateaWhereDataset*, which comes from the *aWhereCharts* R package. 

```{r pull.weather.data}
# query the aWhere API to get forecast data and write to file 
forecast.all <- GetForecastData(template.place, days, years, 
                                write.file = TRUE, filename.out = paste0('outputCSVs/',filename.out))
```

\pagebreak

Let's take a look at the first 10 rows of forecast data.
For a single grid (identified by *locationid*), there are seven rows of forecast data (one per day, identified by *date*). The forecasted precipitation amount (mm) for the grid cell each day is in the *precipitation.amount* column, while the long-term average precipitation amount is in the *precipitation.average* column. 

```{r results=TRUE}
head(forecast.all %>% 
       dplyr::select(locationid, date, precipitation.amount, 
                     precipitation.average), n = 10)
```

For each grid cell, let's add up the forecasted precipitation amount for an n-day forecasted precipitation. Call the *GetForecastSummary* function from the "0-supporting_functions.R" file to aggregate these daily precipitation forecast data into n-day summaries. 

```{r}
# calculate the n-day forecast summaries,
# aggregate weather data over the specified number of days.
forecasts.n <- GetForecastSummary(forecast.all, n.day.forecasts, 
                                  template.place)
```

Let's take a look at the aggregated n-day forecast summaries: 

```{r results=TRUE}
head(forecasts.n %>%
       dplyr::select(locationid, n.day, precip.amount.sum, 
                     precip.avg.sum))
```


# Map forecast summaries

To visualize the forecasted weather data geographically, let's plot the data on a map.

First, let's clip the minimum and maximum values to a set range for mapping.  

```{r}
# create a data frame for the variable thresholds.
# access the variable by referencing the column (thresholds$precip)
# the minimum values is in position 1, maximum value in position 2
thresholds <- as.data.frame(c(thresh.precip.min, thresh.precip.max))
colnames(thresholds) <- "precip"
row.names(thresholds) <- (c("min","max"))
```

## 7-day forecast summary map

```{r results=TRUE, fig.align='center'}
# keep only the 7-day forecast summary values
# clip the precip values to be between 0 and 300mm
forecast.7day <- forecasts.n %>% 
  dplyr::filter(n.day == 7) %>% 
  dplyr::mutate(aPre = ClipValues(precip.amount.sum,
                                  max.thresh = thresholds$precip[2]))

# add geometry information for mapping with ggplot
polygon.df = tibble::as.tibble(wicket::wkt_coords(forecast.7day$shapewkt))
polygon.df$aPre <- forecast.7day$aPre[polygon.df$object] 

# add n-day forecast to output filename
map.title.7 <- paste(filename.out, "7-day_forecast", sep="_")

# create the precip map
precip.map.7 <- ggmap(base.map) +
  geom_polygon( aes( x = lng, y = lat, 
                     group = object, fill = aPre),
                data = polygon.df, alpha = 0.7) +
  scale_fill_gradient2(breaks = seq(0,300, by = 50), 
                       low = "red", mid = "green", high = "blue", 
                       midpoint = 150, limits = c(0,300),
                       name="Precipitation (mm)") +
  ggtitle(map.title.7)

precip.map.7

# save map to file 
ggsave(filename = paste0('figures/',map.title.7, ".png"), 
       precip.map.7, width = 6.02, height = 3.38, units = "in")



```


## 3-day forecast summary map

```{r results=TRUE, fig.align='center'}

# keep only the 3-day forecast summary values
# clip the precip values to be between 0 and 300mm
forecast.3day <- forecasts.n %>% 
  dplyr::filter(n.day == 3) %>% 
  dplyr::mutate(aPre = ClipValues(precip.amount.sum,
                                  max.thresh = thresholds$precip[2]))

# add geometry information for mapping with ggplot
polygon.df = tibble::as.tibble(wicket::wkt_coords(forecast.3day$shapewkt))
polygon.df$aPre <- forecast.3day$aPre[polygon.df$object] 

# add n-day forecast to output filename
map.title.3 <- paste(filename.out, "3-day_forecast", sep="_")

# create the precip map
precip.map.3 <- ggmap(base.map) +
  geom_polygon( aes( x = lng, y = lat, 
                     group = object, fill = aPre),
                data = polygon.df, alpha = 0.7) +
  scale_fill_gradient2(breaks = seq(0,300, by = 50), 
                       low = "red", mid = "green", high = "blue", 
                       midpoint = 150, limits = c(0,300),
                       name="Precipitation (mm)") +
  ggtitle(map.title.3)

precip.map.3

# save map to file 
ggsave(filename = paste0('figures/',map.title.3, ".png"), 
       precip.map.3, width = 6.02, height = 3.38, units = "in")
```





